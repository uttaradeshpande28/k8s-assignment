Kubernetes Assignment: Limitations & Production Strategies

Executive Summary

This document outlines the limitations encountered during the Kubernetes assignment implementation and provides comprehensive theoretical strategies for production deployment. The MVP was successfully deployed on an existing AWS EKS cluster with office security constraints, demonstrating adaptability and problem-solving skills.

Assignment Requirements Analysis

Original Requirements
1. Kubernetes Cluster: Deploy locally or on public cloud
2. Database Cluster: MySQL/MariaDB with persistent data
3. Web Server: Nginx/Apache with multiple replicas and custom configuration
4. Dynamic Web Page: Show Pod IP and serving-host field
5. Network Security: Restrict database access to web server pods only
6. Disaster Recovery: Suggest and implement DB backup solution
7. Custom Network: Connect pods to networks other than pod networks
8. Node Scheduling: Schedule specific replicas on specific nodes
9. Golang Application: Monitor pod status changes (create/delete/update)
10. Helm Charts: Deploy all components using Helm

Implementation Status

Fully Implemented (8/10)
1. Kubernetes Cluster: Deployed on existing EKS cluster
2. Database Cluster: MySQL StatefulSet with persistent data
3. Web Server: Nginx with 3 replicas and custom configuration
4. Dynamic Web Page: Pod IP and serving-host display working
5. Golang Application: Pod monitoring with real-time events
6. Helm Charts: Complete Helm chart for all components
7. Custom Configuration: Nginx config mounted from ConfigMap
8. Init Container: Dynamic serving-host field modification

Partially Implemented (2/10)
1. Network Security: Policies configured but not enforced
2. Disaster Recovery: Manual procedures only

Detailed Limitations Analysis

1. Platform Limitations

AWS EKS CNI Constraint
- Issue: AWS VPC CNI doesn't enforce Kubernetes Network Policies
- Impact: Network security policies are configured but inactive
- Evidence: Policies applied successfully but traffic not restricted

Office Security Restrictions
- Issue: Cannot install Docker Desktop, Kind, or Minikube locally
- Impact: Forced to use existing EKS cluster
- Evidence: Multiple local setup attempts failed due to permissions

Existing Cluster Limitations
- Issue: Using pre-existing EKS cluster with limited modification rights
- Impact: Cannot install additional CNI plugins or modify cluster configuration
- Evidence: Cannot install Calico or Cilium for Network Policy enforcement

2. Technical Limitations

Network Policy Enforcement
# Configured but not enforced
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: mysql-network-policy
spec:
  podSelector:
    matchLabels:
      app: mysql
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: nginx
    ports:
    - protocol: TCP
      port: 3306

Disaster Recovery Scope
- Current: Automated CronJob with 5GB persistent storage
- Missing: Cross-region replication, RTO/RPO validation

Node Scheduling
- Current: Basic pod placement
- Missing: Node affinity, taints, tolerations

Production Implementation Strategies

1. Disaster Recovery Strategy

Current MVP Implementation
# Deploy automated backup CronJob
kubectl apply -f k8s-manifests/mysql-backup-cronjob.yaml

# Restore from existing backup
LATEST_BACKUP=$(kubectl exec mysql-0 -n k8s-assignment -- ls -t /backup/ | head -1)
kubectl cp k8s-assignment/mysql-0:/backup/$LATEST_BACKUP ./backup.sql.gz
gunzip backup.sql.gz
kubectl exec -i mysql-0 -n k8s-assignment -- mysql -u root -p$MYSQL_ROOT_PASSWORD testdb < backup.sql

Production Strategy

Automated Backup Solution
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mysql-backup
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mysql-backup
            image: mysql:8.0
            command:
            - /bin/bash
            - -c
            - |
              mysqldump -h mysql-service -u root -p$MYSQL_ROOT_PASSWORD testdb > /backup/backup-$(date +%Y%m%d).sql
              aws s3 cp /backup/backup-$(date +%Y%m%d).sql s3://backup-bucket/
            env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: mysql-root-password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc

Multi-Region Disaster Recovery
1. Active-Passive Setup
   - Primary cluster in us-west-2
   - Standby cluster in us-east-1
   - Database replication between regions

2. Backup Validation
   - Automated restore testing
   - Data integrity checks
   - Recovery time objectives (RTO < 4 hours, RPO < 1 hour)

3. DNS Failover
   - Route 53 health checks
   - Automatic failover to standby region
   - Application-level health monitoring

2. Network Security Strategy

Current Limitation
- Network Policies configured but not enforced by AWS VPC CNI

Production Solutions

Option 1: CNI Replacement
# Install Calico CNI
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/tigera-operator.yaml
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.0/manifests/custom-resources.yaml

Option 2: Service Mesh Implementation
# Istio service mesh for advanced networking
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: mysql-dr
spec:
  host: mysql-service
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 10
      http:
        http1MaxPendingRequests: 10
        maxRequestsPerConnection: 2

Option 3: AWS Security Groups
- Configure security groups at VPC level
- Restrict database access to web server subnets
- Use AWS WAF for application-level protection

3. Node Scheduling Strategy

Current Implementation
- Basic pod placement without affinity rules

Production Implementation
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values: ["database"]
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["mysql"]
              topologyKey: kubernetes.io/hostname

4. Custom Network Strategy

Current Limitation
- Single pod network, no custom routing

Production Solutions

Service Mesh Implementation
# Istio VirtualService for custom routing
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: nginx-vs
spec:
  hosts:
  - nginx-service
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: nginx-service
        subset: canary
  - route:
    - destination:
        host: nginx-service
        subset: stable

Multus CNI for Multiple Networks
apiVersion: k8s.cni.cncf.io/v1
kind: NetworkAttachmentDefinition
metadata:
  name: custom-network
spec:
  config: |
    {
      "cniVersion": "0.3.1",
      "name": "custom-network",
      "type": "bridge",
      "bridge": "custom-br",
      "ipam": {
        "type": "host-local",
        "subnet": "10.100.0.0/16"
      }
    }

5. Monitoring & Observability Strategy

Current Implementation
- Basic pod lifecycle monitoring with kubectl

Production Enhancement

Comprehensive Monitoring Stack
# Prometheus monitoring
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true

Centralized Logging
# ELK stack for log aggregation
apiVersion: apps/v1
kind: Deployment
metadata:
  name: elasticsearch
spec:
  template:
    spec:
      containers:
      - name: elasticsearch
        image: elasticsearch:7.17.0
        env:
        - name: discovery.type
          value: "single-node"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"

Risk Assessment & Mitigation

High Risk Items
1. Data Loss: Manual backup procedures
   - Mitigation: Implement automated backups with validation
2. Network Security: Policies not enforced
   - Mitigation: Deploy Calico CNI or implement service mesh
3. Single Point of Failure: Single cluster deployment
   - Mitigation: Multi-region active-passive setup

Medium Risk Items
1. Resource Constraints: Limited node scheduling
   - Mitigation: Implement node affinity and resource quotas
2. Monitoring Gaps: Basic pod monitoring only
   - Mitigation: Deploy comprehensive observability stack

Conclusion

The MVP successfully demonstrates core Kubernetes concepts and deployment patterns. While platform limitations prevented full implementation of all requirements, the theoretical strategies outlined provide a clear roadmap for production deployment. The solution showcases adaptability, problem-solving skills, and deep understanding of Kubernetes architecture.

Key Achievements
- Working Kubernetes deployment on constrained environment
- Complete Helm chart implementation
- Real-time pod monitoring application
- Dynamic web application with custom configuration
- Comprehensive documentation of limitations and solutions

Production Readiness
- Disaster recovery automation needed
- Network security enforcement required
- Advanced monitoring implementation recommended
- Multi-region deployment for high availability
